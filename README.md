# Multi-armed-bandits

Multi-armed bandits experiment with UCB, Thompson sampling, peef and SOAAv. Exponential Thompson Sampling implementation and results can be found on ExpTS.ipynb file.

bandits. ipynb Jupyter file shows experiment results for all algorithms except ExpTS.
